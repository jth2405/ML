{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80d74201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12 \n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"training_linear_models\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26b4bd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Exercise: train an SVM classifier on the MNIST dataset. \n",
      "Since SVM classifiers are binary classifiers, you will need to use \n",
      "one-versus-all to classify all 10 digits. You may want to tune \n",
      "the hyperparameters using small validation sets to speed up the process. \n",
      "What accuracy can you reach?\n",
      "\n",
      "\n",
      "First, let's load the dataset and split it into a training set and \n",
      "a test set. We could use train_test_split() but people usually just take \n",
      "the first 60,000 instances for the training set, and the last 10,000 instances \n",
      "for the test set (this makes it possible to compare your model's performance with others):\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nExercise: train an SVM classifier on the MNIST dataset. \\n\"\n",
    "      \"Since SVM classifiers are binary classifiers, you will need to use \\n\"\n",
    "      \"one-versus-all to classify all 10 digits. You may want to tune \\n\" \n",
    "      \"the hyperparameters using small validation sets to speed up the process. \\n\" \n",
    "      \"What accuracy can you reach?\\n\")\n",
    "print(\"\\nFirst, let's load the dataset and split it into a training set and \\n\" \n",
    "      \"a test set. We could use train_test_split() but people usually just take \\n\" \n",
    "      \"the first 60,000 instances for the training set, and the last 10,000 instances \\n\"\n",
    "      \"for the test set (this makes it possible to compare your model's performance with others):\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20317d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lin_clf.fit(X_train, y_train): \n",
      " LinearSVC(random_state=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC, LinearSVC \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784',version=1)\n",
    "\n",
    "X = mnist['data']\n",
    "y = mnist['target']\n",
    "\n",
    "X_train = X[:60000]\n",
    "y_train = y[:60000]\n",
    "X_test = X[60000:]\n",
    "y_test=y[60000:]\n",
    "\n",
    "lin_clf = LinearSVC(random_state=42) \n",
    "print(\"\\nlin_clf.fit(X_train, y_train): \\n\", lin_clf.fit(X_train, y_train))\n",
    "#2017250045 정태환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8609df0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8348666666666666"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = lin_clf.predict(X_train)\n",
    "accuracy_score(y_train,y_pred)\n",
    "#2017250045 정태환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7de60b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lin_clf.fit(X_train_scaled, y_train): \n",
      " LinearSVC(random_state=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float32))\n",
    "X_test_scaled = scaler.fit_transform(X_test.astype(np.float32))\n",
    "#2017250045 정태환\n",
    "lin_clf = LinearSVC(random_state=42)\n",
    "print(\"\\nlin_clf.fit(X_train_scaled, y_train): \\n\", lin_clf.fit(X_train_scaled, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6419b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy_score(y_train, y_pred): \n",
      " 0.9214\n"
     ]
    }
   ],
   "source": [
    "y_pred = lin_clf.predict(X_train_scaled) \n",
    "print(\"\\naccuracy_score(y_train, y_pred): \\n\", accuracy_score(y_train, y_pred))\n",
    "#2017250045 정태환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31ad01ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "svm_clf.fit(X_train_scaled[:10000], y_train[:10000]): \n",
      " SVC()\n"
     ]
    }
   ],
   "source": [
    "svm_clf = SVC(gamma=\"scale\")\n",
    "#2017250045 정태환\n",
    "print(\"\\nsvm_clf.fit(X_train_scaled[:10000], y_train[:10000]): \\n\", svm_clf.fit(X_train_scaled[:10000], y_train[:10000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2361fd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy_score(y_train, y_pred): \n",
      " 0.9455333333333333\n"
     ]
    }
   ],
   "source": [
    "y_pred = svm_clf.predict(X_train_scaled)\n",
    "print(\"\\naccuracy_score(y_train, y_pred): \\n\", accuracy_score(y_train, y_pred))\n",
    "#2017250045 정태환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "549f3490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "\n",
      "rnd_search_cv.best_estimator_: \n",
      " SVC(C=7.116531604882809, gamma=0.0010330768043240405)\n",
      "\n",
      "rnd_search_cv.best_score_: \n",
      " 0.8639897382412353\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, uniform\n",
    "\n",
    "param_dist = {'gamma':reciprocal(0.001,0.1),\"C\":uniform(1,10)}\n",
    "\n",
    "rnd_search_cv =  RandomizedSearchCV(svm_clf,param_dist,cv=3,n_iter=10,verbose=2,n_jobs=-1)\n",
    "rnd_search_cv.fit(X_train_scaled[:1000],y_train[:1000])\n",
    "#2017250045 정태환\n",
    "print(\"\\nrnd_search_cv.best_estimator_: \\n\", rnd_search_cv.best_estimator_)\n",
    "print(\"\\nrnd_search_cv.best_score_: \\n\", rnd_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c40512f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.best_estimator_.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = rnd_search_cv.best_estimator_.predict(X_train_scaled) \n",
    "#2017250045 정태환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc322972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9972833333333333"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, y_pred)\n",
    "#2017250045 정태환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac23a1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9718"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rnd_search_cv.best_estimator_.predict(X_test_scaled) \n",
    "accuracy_score(y_test, y_pred)\n",
    "#2017250045 정태환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60afa21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
